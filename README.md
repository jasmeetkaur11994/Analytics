### Data Analytics 
The repository stores files created during the process of my learning of big data analytics.
The following is the brief description of the files:
1. Data Cleaning using SAS: A SAS project on data cleaning involving removing duplicates and outliers, dealing with missing values, standardizing variables, checking data types, and identifying and resolving inconsistencies in the data. SAS provides a range of tools for data cleaning, including data step programming, SQL, and data quality transformations. This makes it a highly effective tool for data cleaning projects, ensuring that the data being analyzed is accurate and reliable, leading to better decision-making.
2. flipkart.ipynb: Python project on web scraping Flipkart's mobile website using Python can be achieved using libraries such as BeautifulSoup and Requests. The code would involve sending a request to the website, parsing the HTML response with BeautifulSoup, and extracting the desired information such as product names, prices, and specifications using CSS selectors. This data can then be stored in a file or database for further analysis. This code can be automated to extract data for multiple mobile products on Flipkart's website. The results are stored in Flipkart_mobile.csv
3. Scraping_wikipedia_url.ipynb: Python project to scrape Wikipedia, the BeautifulSoup library can be used to extract information from HTML pages. The code would involve accessing the Wikipedia page using Python's requests library, parsing the HTML with BeautifulSoup, and then extracting the desired information using various methods. This code can be automated to scrape multiple pages and gather large amounts of data from Wikipedia.
4. analysis 1.pbix: The Power BI file to perform Exploratory Data Analysis sales analysis of a company
5. current_weather_report (1).ipynb: To display the current weather of a city using Python, web scraping is done using libraries such as BeautifulSoup, Requests, and Selenium. The code would involve sending a request to a weather website, parsing the HTML response with BeautifulSoup or Selenium, and extracting the current weather information such as temperature, humidity, and wind speed using CSS selectors or XPaths. This is automated to display weather information for  a city.
6. imdb.ipynb: Web scraping IMDb film data of top 50 movies achieved using Python and libraries such as BeautifulSoup and Requests. The code would involve sending a request to the IMDb website, parsing the HTML response with BeautifulSoup, and extracting the desired movie information such as title, rating, year, and cast using CSS selectors. This code can be automated to extract data for a movie.

